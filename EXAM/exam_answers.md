## 1. Функции и механизмы ОС, появившиеся на этапе программ-диспетчеров, предшественников операционных систем.

* Сначала компьютеры работали на **архитектуре Фон Неймана**
![img](https://sun9-14.userapi.com/impg/IR2frlkgJ5lfBghMtuPjLp01tvIM7NC3LH1NzQ/7q7oM_iRaAI.jpg?size=1426x610&quality=96&proxy=1&sign=f68e6223db7a14e7240304535814190a&type=album)
  * Суть данной архитектуры заключалась в том, что **cpu** был связан с **ram**, **input**, **output** и **storage**.
  * Проблема **архитектуры Фон Неймана** заключалась в сложности параллельного выполнения программ, так как было сложно достичь синхронизации данных на входе и выходе

#### Задача - распараллеливать процессы, которые проходят через cpu
#### Решение - программа диспетчер
**Программы-диспетчеры** появились для автоматизации загрузки и линковки данных, которые писались под конкретную машину. Когда осознали, что многие части кода повторяются, решили отвести специально место в оперативной памяти для пакетов(библиотек), отсюда возникли задачи:

* автоматизировать линковку (связь приложений с ячейками памяти),

* оптимизировать взаимодействия с устройствами ввода/вывода.


### Задача - оптимизация взаимодействия с устройствами ввода вывода и хранения

* Все пути идут через процессор -> (**при архитектуре Фон Неймана**)
* Проблема - мало **ram** для хранения огромного количества данных, если временные данные хранить в **ram**
* Проблема - процессор при такой работе работает не рационально, потому что выполняет простые операции, которые не используют всю его мощь

##### Таким образом был придуман принципы распараллеливания процессов

При параллельном выполнении процессов возникают сложности:
* Хранилище не гарантирует нам быстрый доступ к данным, из-за этого мы не знаем, когда кончится операция ввода-вывода
* Основная проблема в том, что таким образом нам сложно синхронизировать параллельность разгрузки погрузки памяти
### Функции программ-диспетчеров
##### Спулинг
  * Взаимодействие с input/output/storage занимало очень много времени из-за однозадачности CPU. Распараллеливание будем совершать через простейший процессор - контроллер.
**Спулинг** (SPOOL, Simultaneous Peripheral Output On-Line) - процесс взаимодействия ram/storage через контроллер
  * POOL (спулинг) — спулинг это буферизация данных перед их обработкой
Контроллер сохранял в своих регистрах не только те данные, которые запрашивались, но и те, которые могут потребоваться в ближайшее время.
#### Прерывания
  * **Прерывание** (Interrupt) - специальный сигнал от контроллера к CPU сообщающий о некотором событии (наступлении события), прерывающий ход выполнения текущей программы и передающий управление обработчику прерываний.
  
#### Однопрограммная пакетная обработка
* __Пакет__ – совокупность программных модулей, обрабатываемых данных и конфигураций. 

---

## 2. Функции и механизмы ОС, появившиеся на этапе мультипрограммных операционных систем.

#### Задача: выполнять одновременно несколько задач

##### В чем необходимость ?

* Наши приложения обладают различным поведением, соответственно, они с разной нагрузкой воздействуют на CPU
* Появление псеводопараллельности:
  * Несмотря на то, что процессор "не простаивает", переключение между процессами будет занимать время.
![img](https://sun9-4.userapi.com/impg/fwwgGnoBHluGlrUrFiLw-IcEQYGM4DLb_Gox2Q/ZyDx1drTMmw.jpg?size=712x248&quality=96&proxy=1&sign=519c0d4d4b1a5a4f124ef5f8530f9a68&type=album)

### Функции
 * ##### 1 Задача - обеспечение времени разделения процессора
   * __Что нужно для разделения времени процессора?__
      * Есть 2 процесса. Будем чередовать их выполнение.
      * Как сделать переход ?
      * Нужно запомнить место, где процесс остановился (сохранить контекст процесса).
        * Сохранить значения регистров.
        * Загрузить данные в регистры для нового процесса **(это требует времени)**
    * __Как процессу остановить другой процесс?__
      * __Решение на аппаратном уровне (как контроллер для spooling'a)__
        * Добавили таймер, который через равные промежутки прерывает выполнение процессов.
        * Прерывание - это передача управления процессами диспетчеру прерывания
 * ##### 2 Задача - необходимо разделять память
      * __Virtual Memory__ - способ адресации, при котором каждой программе выделяется виртуальное пространство, адресуемое с нуля. ОС подменяет виртуальный адрес на реальный. Появляется задача защиты областей памяти.
 * ##### 3 Задача - обеспечение защиты программы от действия других программ (задача защиты областей памяти)
    * Надо защищать адресное пространство, т.к. в результате ошибки программиста, мы можем выйти за пределы адресного пространства, при записи туда, возникнет сбой.
    
    * __Механизм защиты памяти - аппаратное решение__

      * Он будет проверять права доступа для записи или чтения
      * Прерывание по защите памяти:
        * Простое решение - уничтожить процесс, которые пытается сделать что-то противозаконное
 
 * ##### 4 Задача - планирование выполнения программы
      * Каждый процесс считает, что он имеет полное адресное пространство, но физическая память ограничена, поэтому нужно планировать использование памяти процессами. ОС также должна решать когда и какой процесс будет выполняться, при каких условиях переключаться.     

 * ##### 5 Задача - задача по синхронизации
    * Нужны механизмы, которые обеспечат межпроцессорную синхронизацию
 * ##### 6 Задача - задача доступа к информации на внешнем хранилище
    * При мультипрограммности появляется проблема контролируемого доступа к данным в хранилище
    * нужно обеспечить очередь
    * Нужно правильно выбрать адреса в хранилище (__для ускорения линковки например__)
      * Можно хранить программы в библиотеке на хранилище и подгружать их (__нужна особая адресация__)
    * __Появляется механизм файлово - каталоговой системы__
      * Даем уникальные имена
      * Группируем их в директории
      * Выстраиваем иерархию между ними
      * Получаем контролируемый доступ к данным в хранилище

--- 
## 3. Функции и механизмы, появившиеся на этапах сетевых и мобильных (универсальных) операционных систем.

### сетевые операционные системы
* Проблемы
  * Много данных
  * Машины очень дорогие
  * Количество потребителей растет => возникает разделение машинного времени среди пользователей
  * Накладные расходы
  * Ввод и вывод - узкое место. Много программ, один оператор, который вводит программ в компьютер -> снижение эффективности использования компьютера
#### Решение - Удаленные терминалы
* Объединим входные и выходные устройства
* Звоним в вычислительный узел и просим что-то вычислить
* Появляется многотерминальная проблема
  * Безопасность - нет оператора, который контролирует ввод и вывод, можно внести вирус
    * Появляется механизм аутентификации и авторизации
    * Вводится понятие пользователя и пользовательский режим
* Появляется удаленное взаимодействие между различными вычислительными узлами
  * есть 2 города с машинами, появляется механизм по обмену данными между машинами
  * __Появляются распределенные операционные системы__

### открытые операционные системы
* Предпосылка
  * Проблема переносимости кода
  * Нужна ось, которая может запускаться на различных компьютерах
* Проблемы:
  * Нужна ось, которая сама по себе будет работать на языке высокого уровня
* Bella boretlis - великая компания
  * Они создают __Unix__ и __C__
  * В 1969 году выходит операционная система unix (__UNICS__), написанная на ассемблере
  * На следующем этапе эта команда разрабатывает язык би и unix переписывается под нее уже существующую версию
  * Выходит 3 редакция с компилятором си 
  * Выходит 4 редакция с ядром, написанным на си
  * Выходит 5 редакция, которая полностью написана на си
  * Таким образом появилась универсальная операционная система **Unix**

## Как появился Linux
* Появился проект GNU (__GNU NOT UNIX__)
  * Разрабатывают компилятор GCC
  * Разрабатываются утилиты и модули на Си
  * Нужно написать ядро
    * Студент Линукс Торвальдс читает Таненбаум и разочаровывается в его оси и в 1991 выкладывает в открытый доступ ось, которая содержит ядро, которое монолитно
    * Таненбаум критикует linux, говоря, что архитектура х86 скоро умрет, а linux написана только под нее.
    * Linux интегрирует Linux с GNU. Так и появилась GNU Linux.
---

## 4.	Задачи и механизмы, реализуемые в рамках функции операционной системы по обеспечению интерфейса между пользовательскими приложениями и аппаратным обеспечением вычислительного узла.

### Основные функции ОС:
* Управление разработкой и исполнением пользовательского программного обеспечения
  * ПО должно быть независимо от аппаратного обеспечения
  * Нужно разработчику дать инструменты, которые абстрагируют его от аппаратного слоя, что реализуется через __API__
  * Реализация API
    * > Мы пишем на java под windows, но мы не задумываемся о том, как устроен интерфейс взаимодействия java с windows. 
    * > Чтение файла: мы не задумываемся о том, как файл читается
* Реализация управления и исполнения программ
    * > Щелкнули по браузеру и он запустился. Произошло множество действий от OS до того, как мы увидели окно браузера.
* Приложение нужно поддерживать ресурсами
* Обнаружение и обработка ошибок
    * Ловим какую-то ошибку и случается сбой
    * Таким образом нам нужно правильно обрабатывать ошибки
* Предоставление высокоуровневого доступа к устройствам ввода/вывода
    * > Мы не задумываемся о том, как устроен ввод/вывод на аппаратном уровне, мы абстрагированы от этого
 * Управление хранением данных - **Store**
    * Обеспечить проверку прав доступа
    * Обеспечить отложенную запись в **Store**
  * Мониторинг ресурсов
    * Приложение должно быть производительным на всех устройствах 
  * Оптимизация использования ресурсов
    * Хотим, чтобы вложенные средства в аппаратное обеспечение продукта работали по максимуму за счет программного обеспечения.
    * Нужен механизм, который обеспечит многокритериальную оптимизацию
    * Одно из таких решений:
      * ![pdca-img](https://cdn8.bigcommerce.com/s-10c6f/product_images/uploaded_images/pdca-circle-image.png)
      * [PDCA](https://ru.wikipedia.org/wiki/%D0%A6%D0%B8%D0%BA%D0%BB_%D0%94%D0%B5%D0%BC%D0%B8%D0%BD%D0%B3%D0%B0) (__Plan-Do-Check-Act__ - __цикл Деминга__) решение - выполняем управление ресурсами и процессами в цикле
        * P - Планирование того, что мы хотим сделать
        * D - Выполнение плана
        * C - Проверка того, что мы хотели выполнить 
        * A - Вносим изменения, если мы не достигли соответствующих показателей
* Поддержка эксплуатации вычислительного узла
  * О Чем речь? Когда используются программы, могут происходить нештатные ситуации с оборудованием, в ос может проникнуть вирус. Для борьбы с такими ситуациями есть ряд механизмов:
    * Системы диагностик - помогают отследить состояние вычислительного узла, например __TOP__ в Linux
    * Средства для восстановления конфигурации ОСи
    * Средства для восстановления данных
      * Создание backup'ов
* Поддержка развития самой операционной системы - появляется новое ПО, новые технологии, мы можем что-то недотестировать и это выяснится в процессе эксплуатации.
  * Механизмы автоматического обновления
  * Механизмы, связанные с изменениями ошибок
---

## 5.	Принципы организации эффективного использования ресурсов компьютера. Критерии эффективности. Подходы к решению многокритериальной задачи.

### Решение многокритериальных задач принятия решений :

* Для работы нескольких программ требуется использование и памяти, и ресурсов процессора. Необходимо использовать и то, и другое эффективно.
* При наличии нескольких критериев (К1, К2, К3 и др.) и при попытке максимизации одного из них, невозможно максимизировать и остальные критерии.

  ### Решения :
1) Использование взвешенных критериев (свертка критериев).
K* = a * K1 + b * K2 + c * K3 + ..., где a + b + c + ... = 1 (весовые коэффициенты). Поиск варианта, при котором значение суперкритерия K* будет максимальным.
Проблема : недопустимость значения одного из критериев.
Так как необходимо обеспечить лучшее время отклика (например, для систем реального вре- мени), вводят условный критерий :
Поиск максимума для одного из критериев, при наличии ограничений на другие критерии.

2) Использование цикла Деминга (PDCA).
Plan (формирование коэффициентов или выбор алгоритма планирования) - Do (последо- вательное выполнение плана) - Check (проверка предсказанных и полученных результатов, достижения целевых показателей) - Act (решение проблем планирования).
---

## 6.	Виды архитектур ядер операционных систем. Общая характеристика каждого вида, достоинства и недостатки.

#### 1 - Монолитная архитектура

  * Все модули находятся в рамках одного адресного пространства, компилируются как совокупность процедур, линкуясь в большой последовательно исполняемый код

  * Монолитная архитектура соответствует принципу модульной организации
  ##### Преимущества:
    1) Быстродействие, все всех видят, каждый может каждого вызвать
    2) Все безопасно - все решения принимаются в ядре
  ##### Недостатки:
    1) Проблемы с надежность, потому что ядро должно быть резидентным, а компонентов очень много
    2) Проблемы с памятью опять же из-за того, что нужно обеспечивать резидентность ядру
    3) Проблема возникает, когда появляется много __services__, появляется необходимость разделить их

#### 2 - Многослойная архитектура (это не новая архитектура, это концепция)
  ##### Преимущества:
    1) Универсальность
    2) Масштабируемость
    3) При сегментировании уровней можно изменять большую часть всего (линукс)
  ##### Недостатки:
    1) Если не линукс, то перезагрузка после изменения чего-либо всё ещё требуется
    2) Ядро всё ещё резидентно
    3) Плохая Производительность
    4) Упирается в производительность памяти и процессора

#### 3 - Микроядерная архитектура
  ##### Преимущества:
    1) В ядре только необходимый код (экономия памяти)
    2) Можно строить распределённые системы (подключать различные сервера, в зависимости от текущих нужд)
  ##### Недостатки:
    1) Низкая производительность (переключение между режимами (kernel и user) серверов и приложений занимает время)
    2) Проблемы с безопасностью (в режим ядра могут попасть опасные приложения и это нужно отдельно контролировать)


#### 4 - Наноядро
Еще меньше функционала оставим в ядре

#### 5 - Экзоядро
Операционные системы, которые были бы разработаны под определенное оборудование. Там с оборудованием разрешают взаимодействовать напрямую. 

---

## 7.	Монолитная архитектура операционной системы. Подробное описание компонентов (слоев), их назначение и взаимодействие между собой. Достоинства и недостатки монолитной архитектуры ядра.

![img](https://sun9-69.userapi.com/impg/j2Hl8AptmhyVkdU5f1fdP5Fqyd_zLUtqhizAWA/Ygnu9MN1_Eo.jpg?size=1074x666&quality=96&proxy=1&sign=af030bbdacaf11daec5832e2fdb45120&type=album)

> Все модули находятся в рамках одного адресного пространства, компилируются как совокупность процедур, линкуясь в большой последовательно исполняемый код
__Монолитная архитектура соответствует принципу модульной организации__
### Выделили несколько слоев монолитной архитектуры
* __Main program__ - один модуль, взаимодействует с сервисами, может и с утилитами
* __Services__ - совокупность модулей, взаимодействует с утилитами
* __utilities__ - совокупность модулей, взаимодействует с аппаратным обеспечением

### Зачем нужно такое разделение ?
* Есть пользовательское по
* Есть аппаратное обеспечение
* Утилиты - это драйвера, они обеспечивают взаимодействие с реальным оборудованием, каждая утилита реализует протокол взаимодействия с контроллером
* Main program - это интерфейс, который обеспечивает системный вызов
  * > Какое-то пользовательское программное обеспечение делает __SYSTEM CALL__ и __Main program__ понимает, какие ресурсы нужно выделить и что сделать, чтобы обработать этот системный вызов
  * Как это происходит ?
    * Пользовательское __по__ вмещает в свое адресное пространство в качестве параметров некий идентификатор системного вызова (например получение файла) и инициирует программное прерывание. В этот момент управление переходит к ядру, ядро смотрит на системный вызов и понимает, что с ним нужно сделать. Теперь нужно его выполнить:
      * __Utilities__ могут работать только с железом, поэтому выделяется средний слой __services__
      * __Main program__ дергает один или совокупность __services__
      * __Services__ дергают __utilities__ и обеспечивает выполнение задачи или выкидывает ошибку, докладывает главной программе, сообщив об успешном выполнении или выдавая ошибку
#### Преимущества монолитной архитектуры
* Быстродействие, все всех видят, каждый может каждого вызвать
* Все безопасно - все решения принимаются в ядре
#### Недостатки монолитной архитектуры
* Проблемы с надежность, потому что ядро должно быть резидентным, а компонентов очень много
* Проблемы с памятью опять же из-за того, что нужно обеспечивать резидентность ядру
* Проблема возникает, когда появляется много __services__, появляется необходимость разделить их

---

## 8.	Концепция многослойного ядра операционной системы. Подробное описание слоев, их назначение. 

 Многослойная архитектура (это не новая архитектура, это концепция)

 ![img](https://sun9-21.userapi.com/impg/XEzDSf2objqDyK7PQQOLR80nF0yIKYX7O_O-Hg/b02ozyuQ4LQ.jpg?size=988x430&quality=96&proxy=1&sign=83d84619d9022931fda9afc557fc0b9d&type=album)
 
__Наша операционная система это набор концентрических слоев:__
* __Hard ware__
* __Средство аппаратной поддержки ядра__
  * Система прерываний
  * Средство связанной с поддержкой привилегированного режима
  * Средство поддержки виртуальной памяти
  * Смена регистровых контекстов (сохранение состояний регистров)
  * Системный таймер 
  * Защита памяти
* __Машинно зависимые модули (HAL)__
  * Это та часть кода ядра, которая зависит от конкретной платформы. Независимость от программного обеспечения, система должна иметь возможность работать с разным железом.
* __Базовые механизмы ядра__ - модули которые могут работать с нужными структурами данных, они обеспечивают выполнение плана, сгенерированного менеджером ресурсов
* __Менеджеры ресурсов__ - составляет план выполнения команд
* __Слой интерфейса - API - слой системных вызовов__
* __Снаружи находится наше программное обеспечение__

__Если архитектура монолитная, то все эти слои организованны в ядре__
 ##### Преимущества:
    1) Универсальность
    2) Масштабируемость
    3) При сегментировании уровней можно изменять большую часть всего (линукс)
  ##### Недостатки:
    1) Если не линукс, то перезагрузка после изменения чего-либо всё ещё требуется
    2) Ядро всё ещё резидентно
    3) Плохая Производительность
    4) Упирается в производительность памяти и процессора


---

## 9.	Микроядерная архитектура операционной системы. Подробное описание компонентов, их назначение и взаимодействие между собой. Достоинства и недостатки микроядерной архитектуры ядра.

![img](https://sun9-50.userapi.com/impg/nWE8on7nHHG44fOqvXrpQseukQnqhVwtAoJwaQ/qf4Cnq8MfJo.jpg?size=1298x620&quality=96&proxy=1&sign=96b1db08d3524fe16136c8bd41a0d015&type=album)
### Описание компонентов
* __Микроядро__ - Микроядро защищено от остальных частей ОС и приложений. В состав микроядра обычно входят машинно-зависимые модули, а также модули, выполняющие базовые (но не все!) функции ядра по управлению процессами, обработке прерываний, управлению виртуальной памятью, пересылке сообщений и управлению устройствами ввода-вывода, связанные с загрузкой или чтением регистров устройств.
* __Сервера ОС__ - компоненты ОС, обслуживающие запросы приложений пользователей, утилит и системных обрабатывающих программ, менеджеры ресурсов, здесь они вынесены в пользовательский режим. 
* __Средства аппаратной поддержки ОС__ - различные утилиты.


#### Как именно эта архитектура работает ?
* Предположи(нить)м, что приложение решило, что ему нужно сделать какую-то операцию, оно делает вызов в ядро, ядро допустим приняло решение, что нужно выделить память, сервер памяти выделит память и вернет результат в ядро, ядро вернет результат в приложение.


![img](сюда вставить)

### В чем плюс этой архитектуры ?
* __Простота реализации__ (ядро и компоненты реализуют чётко определённую функциональность, поэтому размер их кода невелик);
* __Простота отладки__ (компоненты — обычные процессы, поэтому могут отлаживаться с помощью инструментов, созданных для отладки процессов);
* __Надёжность__ (в ОС с микроядерной архитектурой ошибка в одном из компонентов приведёт к завершению процесса компонента; в ОС с монолитным ядром отказ компонента приведёт к отказу ОС);
* __Модульность__ (в микроядерной ОС большее число компонентов может быть запущено и остановлено по необходимости; например, для исправления ошибки можно внести изменения в код компонента, скомпилировать новый компонент, остановить старый и запустить новый)

### В чем минусы?
* __Производительность__ - нужно производить много переключений, на что будет тратиться время.

---

## 10.	Понятия процесса, потока, нити, задания. Их определения, назначение и различия между собой.

#### Процесс - совокупность набора исполняемых команд, ассоциированных с ними ресурсов и статуса исполнения, находящаяся под управлением ОС.
* Процесс существует до тех пор, пока система может им управлять.
* Каждый процесс уникален для ОС.
* Существует возможность запустить один и тот же процесс несколько раз, но у каждого из запущенных процессов будет свой (различный) статус.
* Процессу выделяется адресное пространство, при этом ОС следит за тем,чтобы процессы не трогали чужие адресные пространства (идея изоляции процессов)

#### Поток - подчасть процесса, оперирующая с одним определённым адресным пространством и выполняющая часть набора команд.
* Разделение процесса на потоки происходит на уровне ОС.
* Несколько потоков одного процесса имеют доступ к одним и тем же ресурсам.
* Потоки не защищены друг от друга.
* Потоки имеют разное время исполнения, т.е. происходит изолирование потоков.

#### Волокно - это составляющая потока, которым управляет сама программа, а не ОС.
* Помогает избежать проблем с планировщиком (например, если один поток еще не закончит работать, а результаты его работы нужны другому потоку), которые были до этого.
* Идея примерно в том, что один поток может содержать несколько волокон, при этом для них существует общая память и прочие ресурсы.
* Волокна выполняются ТОЛЬКО в пользовательском режиме (не привилегированный доступ и не режим ядра).
* Волокна работают в промежутки времени, выделенные системой для потока, и внутри этого времени они выполняются последовательно, а кому сколько работать - определяется в программе.

#### Задание 
Несколько процессов объединяются в задания для ограничения общих ресурсов. 
* Задание имеет лимиты для количества ресурсов, которое может для себя просить и квоты на максимальное количество процессов.


### Еще раз подытожим хуй залупа пизда манда бля иди в очко
* __Задание__ - совокупность процессов, квоты на их количество и лимитов на ресурсы. 
* __Процесс__ - некоторая заявка для ОС, содержащая в себе инструкции, которые необходимо выполнить. ОС распределяет между ними все ресурсы КРОМЕ процессорного времени.
* __Поток__ - то, из чего состоит процесс, как раз между потоками распределяется процессорное время. Это могут быть как части программы, выполняющие один и тот же код на разных адресных пространствах, чтобы “распараллеливать”, так и разные инструкции, выполняемые параллельно.
* __Волокно__ - составляющее потока. Волокна внутри потока имеют общие ресурсы, в том числе и общее процессорное время. Но при этом, выполняются параллельно, а безопасность их работы - забота программиста.

---
## 11.  Функции подсистемы управления процессами.

####Подсистема управления процессами - одна из основных подсистем, влияющих на функционирование компьютера.

##### К основным функциям этой подсистемы относят: 
    1) создание процессов и потоков
    2) обеспечение процессов и потоков необходимыми ресурсами
    3) изоляция процессов
    4) планирование выполнения процессов и потоков
    5) диспетчеризация потоков
    6) организация межпроцессного взаимодействия
    7) синхронизация процессов и потоков
    8) завершение и уничтожение.
##### Создание процессов
При загрузке ОС обычно создаются несколько процессов (высокоприоритетные и фоновые). Новый процесс может быть создан по запросу текущего. 
##### Обеспечение процессов ресурсами
ОС поддерживает в памяти информационные структуры, в которые записывает какие ресурсы выделены каждому процессу. Некоторые ресурсы выделяются при создании, а некоторые по запросу во время выполнения (динамически). Ресурсы могут быть выданы процессу на время его жизни или только на определенный период.
##### Изоляция процессов
Для того, чтобы процессы не могли вмешиваться в распределение ресурсов, а также не могли повредить данные друг друга, задачей ОС является изоляция одного процесса от другого. Для этого ОС обеспечивает каждый процесс отдельным адресным пространством.
##### Планирование и диспетчеризация процессов и потоков
Процесс рассматривается как заявка на потребление всех видов ресурсов, кроме  процессорного времени. Этот ресурс распределяется между потоками. Переход от выполнения одного потока к другому выполняется в результате планирования и диспетчеризации. 

  * Планирование - работа по определению момента, в который необходимо прервать выполнение текущего потока и начать выполнять другой поток.

  * Диспетчеризация заключается в реализации решения, найденного в результате планирования, т.е переключение с одного потока на другой. Проходит в три шага:
    1) Сохранение контекста текущего потока.
    2) Загрузка контекста выбранного потока в результате планирования
    3) Запуск нового потока на выполнение
##### Синхронизация потоков
Синхронизация потоков является важной функцией подсистемы управления процессами и потоками. ОС представляют множество механизмов синхронизации(семафоры,мьютексы и т.д), все эти механизмы работают с потоками, а не процессами. Поэтому когда один поток блокируется на семафоре, другие потоки процесса могут продолжить работу.
##### Завершение процессов
Каждый раз когда процесс завершается, ОС предпринимает шаги, чтобы “зачистить следы” его пребывания в системе. Подсистема управления процессами закрывает все файлы, с которыми работал процесс, и освобождает оперативную память, отведенную под него, завершает его потоки.


---
## 12.  Методы создания процессов в различных операционных системах. Структуры данных о процессах.

Нужно хранить такую информацию о процессе, что в любой момент времени можно его приостановить так, что в любой другой момент времени можно было его запустить с того самого места, где он приостановился. 

#### Структуры данных о процессах:
* Основные структуры данных о процессе хранятся в PCB (Process Control Block), они могут описать процесс
#### Таблица процессов
Здесь хранятся такие данные, как: 
> 1) Информация по идентификации процесса PID– Process IDentificator; 
> 2) PPID – Parent PID – хранится для того, чтобы обрабатывать код возврата от дочернего процесса, и, если этот процесс аварийно завершится, обработать ошибку (если обработчика нет, то процесс просто удаляется). Все, кто потерял родительский процесс усыновляются init`ом;
>3) UID информация о пользователе, который запустил этот процесс;
> 4) Регистровая информация;
> 5) Важная информация по управлению процессом -  все данные, для принятия решения по управлению процессом(например, приоритет или статистика использования процесса).

__Zombie процесс__ – процесс, который завершил работу, освободил ресурсы и отправил код завершения родителю, ожидая освобождения PID’а, который он занял, но родитель по каким-то причинам не отреагировал на этот код и не завершил дочерний процесс. 

Процесс в итоге остаётся занимать место в таблице PID’ов, не занимая при этом ресурсов. Init, в свою очередь, не может удочерить этот процесс, так как по факту у него есть родитель, просто этот родитель не позаботился о своём дочернем процессе и не завершил его как следует.

#### Пространство процесса
Эта дополнительная информация, которая требуется ядру ОС во время исполнения процесса, например: заголовки исполняемых файлов, корневой и текущий каталоги и т.д.

__Важно понимать, что выше написанное относится к Unix подобным системам.__ В Windows мы не храним информацию о родителях, а вся информация хранится в виде набора связанных структур. 		

#####Linux
В Linux иерархическая система – каждый процесс знает кем он порожден и помнит своего родителя. Первоначальный процесс init имеет PID = 1. Породить процесс – породить описание процесса. Ни один процесс не сможет получить доступа и ресурсов больше, чем было дано родителем.

#####Windows
Процессы порождаются менеджером процессов, что помогает избегать zombie процессов, но отсюда проблема с безопасностью. Причем самое интересное: все процессы равноправны и любому процессу можно поставить некий маркер (дескриптор), позволяя управлять дочерними процессами, тем самым нарушая иерархию процессов. В этом и есть проблема с безопасностью: может возникнуть проблема с тем, что один процесс монополизирует все ресурсы. 


---
## 13.  Модель жизненного цикла процесса: состояния процесса, правила переходов между состояниями.
#### Двухуровневая модель
__Шаги: исполняется, не исполняется.__ 
* Любому процессу при его рождении присваивается статус «не исполняется». 
* Как только планировщик выбирает этот процесс для исполнения, процесс получает статус «исполняется». 
* Поле исполнения он может завершиться, либо снова получить статус «не исполняется» и ожидать время на исполнение. 
![img](https://sun9-14.userapi.com/impg/be5LGux-0KmDX5N7OiFp7eOqOShuM7sNE8hQuw/gttV36nNHBo.jpg?size=536x338&quality=96&proxy=1&sign=e0dac292fe9d5c945406ccbc8b677b5f&type=album)

Процесс, находящийся в состоянии процесс исполняется, может быть завершен ОС или приостановлен и снова переведен в состояние процесс не исполняется. Приостановка процесса происходит по двум причинам: для его дальнейшей работы потребовалось какое-либо событие (например, завершение операции ввода-вывода) или истек временной интервал, отведенный операционной системой для работы данного процесса. 

После этого ОС по определенному алгоритму выбирает для исполнения один из процессов, находящихся в состоянии не исполняется, и переводит его в состояние исполняется. Новый процесс первоначально помещается в состояние не исполняется. 

Это очень грубая модель, она не учитывает, в частности, то, что процесс, выбранный для исполнения, может все еще ждать события, из-за которого он был приостановлен, и реально к выполнению не готов.

#### Трехуровневая модель
__Шаги: исполнение, готовность, ожидание.__ 
* Процесс при порождении может выполняться. 
* Из готовности планировщик переводит процесс в статус «исполняется». 
* После исполнения процесс либо завершается, либо отправляется в ожидание/готовность. За состоянием ожидания следит определенный процесс ядра ОС. 
* После прерывания ожидания процесс переходит в статус готовности. И снова к исполнению. 

![img](https://sun9-34.userapi.com/impg/3V8LqvF_RT4LmeP0DLCI752IJ2MI2E_w2SXEtA/lvW1XTClRA8.jpg?size=534x378&quality=96&proxy=1&sign=68c3cd16dcf2c9092a010039d8d17c6d&type=album)


Новый процесс попадает в состояние готовность. ОС, пользуясь каким-либо алгоритмом планирования, выбирает один из готовых процессов и переводит его в состояние исполнение. В состоянии исполнение происходит непосредственное выполнение программного кода процесса. 

Выйти из этого состояния процесс может по трем причинам:
* ОС прекращает его деятельность;
* Он не может продолжать свою работу, пока не произойдет некоторое событие, и ОС переводит его в состояние ожидание;
* В результате возникновения прерывания в вычислительной системе (например, прерывания от таймера по истечении предусмотренного времени выполнения) его возвращают в состояние готовность.

Из состояния ожидание процесс попадает в состояние готовность после того, как ожидаемое событие произошло, и он снова может быть выбран для исполнения. 

Наша новая модель хорошо описывает поведение процессов во время их существования, но она не акцентирует внимания на появлении процесса в системе и его исчезновении.

#### Пятиуровневая модель
Рождение – растянутый этап, на котором ОС решает, стоит ли рождать этот процесс. На этом этапе у процесса нет PCB. 
* После рождения процесс переходит в статус «готовность». 
* Из готовности планировщик переводит процесс в статус «исполняется». 
* После исполнения процесс либо завершается, либо отправляется в ожидание.
* За состоянием ожидания следит определенный процесс ядра ОС. 
* После прерывания ожидания процесс переходит в статус готовности. И снова к исполнению. 
* Завершение – растянутый этап завершения процесса: освобождения памяти, нахождение родителя. процесс находится в завершении значительное время пока ОС в поисках. 

![img](https://sun9-36.userapi.com/impg/OxkbV3Kkzly-l0Hc85YJeljoaoL9Vpqb13SSfA/WX3-G0DwSjs.jpg?size=542x458&quality=96&proxy=1&sign=0ab3e9eaccdc0d223e3c107f811cdef3&type=album)

Теперь для появления в вычислительной системе процесс должен пройти через состояние рождение. При рождении процесс получает в свое распоряжение адресное пространство, в которое загружается программный код процесса; ему выделяются стек и системные ресурсы; устанавливается начальное значение программного счетчика этого процесса и т. д. Родившийся процесс переводится в состояние готовность. При завершении своей деятельности процесс из состояния исполнение попадает в состояние закончил исполнение.

#### Семиуровневая модель
Шаги: пятиуровневая модель + исключительная ситуация + зомби-состояние (только для Linux).
* Если в процессе исполнения возникает ошибка, процесс отправляется в исключительную ситуацию. После решения ошибки из исключительной ситуации процесс получает статус готовности.
* Выход из зомби процесса не всегда возможен.

![img](https://sun9-61.userapi.com/impg/lYnmMfxDHympW4U4ohEhl9uLGskgYVDp2qsoSQ/-H8j2dtU418.jpg?size=546x468&quality=96&proxy=1&sign=2737a01740a7f44ce76de782255c8d77&type=album)


---
## 14.  Виды планирования и их место в жизненном цикле процесса.
Основная цель планирования вычислительного процесса заключается в распределении времени процессора (нескольких процессоров) между выполняющимися заданиями пользователей таким образом, чтобы удовлетворять требованиям, предъявляемым пользователями к вычислительной системе. Такими требованиями могут быть, как это уже отмечалось, пропускная способность, время отклика, загрузка процессора и др.

Все виды планирования, используемые в современных ОС, в зависимости от временного масштаба, делятся на долгосрочное, среднесрочное, краткосрочное и планирование ввода-вывода. Рассматривая частоту работы планировщика, можно сказать, что долгосрочное планирование выполняется сравнительно редко, среднесрочное несколько чаще. Краткосрочный планировщик, обычно работает, определяя, какой процесс или поток будет выполняться следующим. 

####Виды планирования:
  * Долгосрочное — между рождением и готовностью (запуск процесса влечёт за собой требование процессорного времени и памяти)
  * Среднесрочное — Решение о добавлении процесса к числу процессов, полностью или частично размещенных в основной памяти. Сбрасывание из оперативной памяти не скоро выполняющихся процессов.
  * Краткосрочное — между готовностью и исполнением. Решение о том, какой из доступных процессов (потоков) будет выполняться процессором следующим. 
  * Планирование доступа к внешним устройствам.

![img](https://sun9-24.userapi.com/impg/jWm40ppp9UqGoRt1JMEk1FwmMowQ6ZpVgMrsBQ/GBoyYwZWdeA.jpg?size=1442x1168&quality=96&proxy=1&sign=15423bcc63c56f6e5b901d9ce3e47279&type=album)



---
## 15.  Критерии эффективности и свойства методов планирования процессов, параметры планирования процессов.
Для каждого уровня планирования процессов можно предложить много различных алгоритмов.
Выбор конкретного алгоритма определяется классом задач, решаемых вычислительной системой, и целями, которых мы хотим достичь, используя планирование.

#### Критерии:
1. __Справедливость__ - равномерно раздавать ресурсы всем потребителям.           
    * Утопическое понятие.
    * Противоречие эффективности.
    * Гарантировать каждому заданию или процессу определенную часть времени использования процессора в компьютерной системе, стараясь не допустить возникновения ситуации, когда процесс одного пользователя постоянно занимает процессор, в то время как процесс другого пользователя фактически не начинал
выполняться.
2. __Эффективность__ - постараться занять процессор на все 100% рабочего времени, не позволяя ему простаивать в ожидании процессов, готовых к исполнению.
3. __Полное время выполнения__ - время от того как процесс впервые попал в готовность до того, как он завершился.
4. __Время ожидания__ - сократить время, которое проводят процессы в состоянии готовность.
5. __Время отклика__ – минимизировать время, которое требуется процессу в интерактивных cистемах для ответа на запрос пользователя

#### Свойства алгоритмов планирования: 
 1. __Предсказуемость__ - если многократно на одних и тех же данных запустить алгоритм, то результат должен быть примерно одинаковым
 2. __Минимальные накладные расходы__ (В ОС нет сложных алгоритмов) - соотношения времени выборки процесса на исполнение и времени исполнения должны быть существенны.
```
Если на каждые 100 миллисекунд, выделенные процессу для использования процессора, будет приходиться 200
миллисекунд на определение того, какой именно процесс получит процессор в свое распоряжение, и на
переключение контекста, то такой алгоритм применять не стоит.
```
3. __Масштабируемость__ - алгоритмы не должны терять работоспособность при увеличении нагрузки.

#### Параметры планирования 
Параметры планирования – то, что мы знаем о системе и процессах , для того, чтобы планировать.
##### Статические параметры
На этапе загрузки процесса появляются статические параметры
* Каким пользователем запущен процесс;
* Приоритет задачи;
* Сколько процессорного времени запрошено для решения задачи;
* Каково соотношение процессорного времени и времени, необходимого на операции ввода/вывода;
* Какие ресурсы, и в каком количестве необходимы (оперативная память, устройства ввода/вывода, специальные библиотеки).
##### Динамические параметры
Динамические параметры появляются после первого исполнения
* Сколько времени прошло со времени выгрузки процесса на диск или загрузки его в оперативную память;
* Сколько оперативной памяти занимает процесс;
* Сколько процессорного времени было предоставлено процессу.


---
## 16.  Методы планирования без внешнего управления приоритетами (FCFS, RR, SJF), гарантированное планирование. Описание каждого метода, их достоинства и недостатки.

#### FCFS - First Come, First served
Простая аналогия - FIFO. Выстраивается очередь из процессов и каждый выполняется по порядку.

Такой алгоритм выбора процесса осуществляет невытесняющее планирование. Процесс, получивший в свое распоряжение процессор, занимает его до истечения текущего CPU burst(Время на процессоре) . После этого для выполнения выбирается новый процесс из начала очереди.

##### Пример:
__Тут хуевый порядок процессов__
![img](https://sun9-11.userapi.com/impg/e6SSqBcJjquW6PAGzBOYv-Mf6V-oVRVoI8c_gQ/nvCXP87_D4M.jpg?size=1210x1428&quality=96&proxy=1&sign=fbddfbc336ef37ee5da0591cbd7b7721&type=album)

__Тут нормальный__
![img](https://sun9-20.userapi.com/impg/CmaDpIyOOcTJEq-dfgWgYu-m4KnW-XaOzwktfQ/0gsfsN62NLM.jpg?size=1330x1190&quality=96&proxy=1&sign=32a0bccd1e7d169eef01edbb041a9eb5&type=album)

##### Преимущества
* Прост в реализации.
##### Недостатки
* Время работы алгоритма для конкретной очереди процессов зависит от расположения процессов в очереди. 


#### RR - Round Robin 
##### Описание
По своей сути, алгоритм является модификацией FCFS, он реализован  в режиме вытесняющего планирования. 

Принцип работы можно представить, если вообразить колесо обозрение, в котором каждая кабинка - это процесс и она проходит через нижнюю точку - процессор на определенный квант(промежуток) времени. Пока кабинка проходит над процессором, она может его использовать, чтобы исполнится.

Говоря, как еблан, каждому процессу в очереди дается время на процессоре (заранее выбранный квант времени), если он выполнился - сьебал из очереди и пошел следующий процесс, не успел - пошел в конец очереди заново ждать и идет следующий процесс.

##### Пример:
__Квант времени 4__
![img](https://sun9-24.userapi.com/impg/JG7FdsntznYObmG7Xje5kzomZkIWNSCc-SjEGA/vtyEpWBs6L4.jpg?size=1368x1076&quality=96&proxy=1&sign=2162c3c02801c48a12f44a1f3bbb0b53&type=album)

__Квант времени 1__
![img](https://sun9-62.userapi.com/impg/E320WTHUg9AkLWZ3Poi-IfchBgtf7dLRQ3wcnw/9CDBlH0Zur4.jpg?size=1292x814&quality=96&proxy=1&sign=9c606d04870ac8f5a32c041178e8cf0e&type=album)

##### Преимущества 
* Простота реализации
* При правильно подобранном кванте времени, выдает оптимальный результат
##### Недостатки
* При очень больших квантах времени, когда CPU burst меньше его, алгоритм вырождается в FCFS.
* При очень маленьких квантах времени появляются накладные расходы на переключения контекста, которые значительно снижают производительность системы.



---
## 17.  Приоритетное планирование с внешним управлением приоритетами, многоуровневые очереди. Описание методов, их достоинства и недостатки.

**Приоритетным планированием** называется планирование, при котором каждому процессу присваивается определенное числовое значение – приоритет. 

Приоритет может задаваться как внутренними критериями системы (например, длительность CPU burst для SJF), так и внешними по отношению к системе. 

- **Внешние критерии** чаще всего являются важность процесса для пользователя (или важность пользователя) или количество профита, полученного за выполнение процесса (например, в денежном эквиваленте). Например, процесс, запущенный пользователем “администратор” имеет приоритет выше процесса “рядового пользователя”. Или процесс, за выполнение которого заплатили больше денег, будет дольше занимать процессорное время.

  **Достоинства:**
  

  **Недостатки:**

- **Многоуровневые очереди** были придуманы для более гибкого планирования работы процессов. С помощью таких очередей процессы можно разбить на группы, группе дать свой приоритет и пока в группе с более высоким приоритетом есть процессы для исполнения, процессорное время не будет передано процессам из группы с более низким приоритетом. 

    Получается, что каждая группа является отдельной очередью, при этом сами по себе группы-очереди находятся в одной большой очереди из групп.

    **Достоинства:**

    **Недостатки:**



---
## 18.  Организация планирования процессов в ОС семейств Microsoft Windows

### Внешнее управление приоритетами процессов
> Основывается на идее многоуровневых очередей
* Их 32
* Чем больше номер очереди тем выше приоритет
* Если несколько процессов находится в той или инной очереди, то между собой такие проецссы переключаются на основе алгоритма Round Robin
* Самая верхняя часть очереди с 1 по 16 - __Real time processes__
  * Процесс никогда никуда не переместится в очереди операционной системой
* Самая нижняя часть очереди с 0 по 15 - __Dynamic time processes__
  * Операционная система может менять очереди для процессов
  * Процесс, когда ему меняют приоритет, оне не может выйти за пределы своей группы
* Самая низкая очереди - 0 очередь, очередь обнуления страниц в памяти
  * Зачем это нужно ?
    * Когда процесс завершается, мы осводождаем адресное пространство, но данные этого процесса там остались
    * И если мы выделяем время другому процессу, то данные эти этот процесс можем прочитать. Это могут быть какие-то конфедициальные данные. Тогда можно написать вредоносную программу, которая будет завершать процессы и искать, нет ли чего-то полезного в оставшихся данных. 


|Queue number|---------|
|------------|---------|
|31||
|...||
|...||
|...||
|16||
|15||
|...||
|...||
|...||
|1||
|0||

#### Есть 6 классов приоритетов процессов
* Real time - 24 queue
* High - 13 queue
* Above normal - 10 queue
* Normal - 8 queue
* Below normal - 6 queue
* Idle - 4 queue
> То есть процессы, создаваясь, по умолчанию попадают в одну из этих очередей и имеют заданный приоритет. Но в процессе алгоритма планирования операционной системой этих процессов, процессы могут прыгать из одной очереди в другую

* Обычный непривелигированный пользователь не можем поставить свой процесс Real time queue
  * Но пользователь с правами доступа администратора может засунуть процесс в Real time queue

> Все процессы как правило помещаются в normal очередь

* Процесс - это еще и множество потоков
  * Таким образом планировщик по сути еще и управляет потоками  
  * И это тоже может быть внешне управляемым

#### Уровни насыщения
* Time critical +15
* Highest +2
* Above normal +1
* Normal ± 0
* Below normal -1
* Lowest -2
* Idle -15

* В чем идея уровней насыщения?
  * Мы выставляем для процессам класс в очереди
  * Когда будет выполняться код, для конкретного потока в процессе можно будет задать класс насыщения
  * Все уровни кроме Time critical и Idle
    * Не позволяют выйти выше своей очереди
  * В Time critical и Idle
    * можно менять уровень насыщения
  * Но Time critical и Idle при смене своего уровня насыщения не могут выходить за пределы группы, в которой они состоят (Real time и Dynamic time)

## Внутреннее управление приоритетами процессов
### Как оно устроено ?
* Операционная система для динамических приоритетов может их менять в зависимости от того, как изменился статус процесса после их выполнения
* Когда она можем менять приоритет ?
  * Вышел после дисковой опреации, приоритет увеличился на 1
  * Вернулся с полседоватеьлной опреации на порте, приоритет увеличился на 2
  * Вернулся с клавиатуры, приоритет увеличился сразу на 6 (для обеспечения времени отклика)
  * Для звукового процессора, приоритет увеличился на 8
  * И так далее...

> Эти изменения делаются не вечно
* В Windows вводится понятие кванта, которые вычисляется через таймер
  * Соответственно, процесс получил на 2 кванта жить в приориттеной очереди
  * И Если он не испольщовал полностью этот квант(например ушел в ожидание). То он может продолжить выполнение в это очереди оставшееся количество квантов.
  * Если он не ушел в ожидание и потратил все кванты 
    * Мы его вкидываем на очередь ниже и так далее до самого низа
* В Windows процесс может быть в низкоприоритетной очереди, что может вызвать голодание этого процесса. 
  * В Windows пошли путем создания специального компонента, который понимает, что какой-то процесс ждет боле 4 секунд
    * Если процесс ждет больше 4 секунд, ему на 1 квант даем сразу 15 очередь, чтобы он мог разгрузиться;
    * Это сделано для того, чтобы минимизировать возможность тупика

---
## 19.  Принципы работы планировщиков O(1) и CFS в операционных системах GNU/Linux.
        > До 2.6 в Linux использовался планировщик, который работал за O(n)
#### Его идея
* У нас было n процессов, они были упорядочены по определенному признаку
* Выбирался процесс с наилучшим признаком
* В худшем случае, нужно было перебирать все значения признаков за колиство процессов

#### При появлении Java стали появляться многопоточные программы
Таким образом алгоритм за О(n) стал очень плохо работать в связи с тем, что в одном процессе могли быть сотни потоков, которые нужно было перебирать

#### Появился планировщик, который назывался O(1)
> Работал он за константу

* Каждый центральный процессор для планировщика O(1) представлен в виде многоуровневой очереди со 140 очередями
* В Linux все наоборот относительно Windows, очереди с менеьше номером имеют больий приоритет

|Queue number|smth|
|------------|----|
|1||
|...||
|...||
|...||
|100||
|101||
|...||
|...||
|...||
|140||

* Тут такая же идеология как и в Windows
  * Real time
  * Dynamic time
  * В Linux мы не можем за счет прав рута вывести пользовательский процесс в Real time
* Пользователь может в любой очереди менят приоритет своего процесса
  * Есть значение nice от -20 до +19
* Внутри очередей процессы живут в рамках Round Robin
* Квант выполнения зависит от значения nice в определенной очереди
  * Например при значении nice равным -20 мы можем дать очереди 200мс
  * При nice = 19, мы можем дать 10мс

##### Что произойдет с процессом, когда мы дадим ему выполниться ?
* У нас по факту есть 2 группы очередей, они одинаковы (__Active и Non Active__)
* Процессу отведем определенный квант времени
  * Если процесс сам ушел в ожидание(не потратив весь квант времени)
    * Он вернется и встанет в конец очереди
  * Если процесс выполнялся и потратил весь квант времени
    * Тогда мы помещаем его во 2 таблицу
      * Постепенно все процессы будут уходить во 2 очередь 

|Queue number|queue|     |Queue number|queue| 
|------------|-----|-----|------------|-----|
|1           |     |     |1           |     |
|...         |     |     |...         |     |
|...         |     |     |...         |     |
|...         |     |     |...         |     |
|100         |     |     |100         |     |
|101         |     |     |101         |     |
|...         |     |     |...         |     |
|...         |     |     |...         |     |
|...         |     |     |...         |     |
|140         |     |     |140         |     |

##### Это гарантирует нам отсутствие голодания
> Потому что рано или поздно все процессы уйдут во 2 очередь, а значит получат свой квант времени на выполнение
##### С другой стороны, выделяя кванты разного времени, мы даем возможность нетребовательным процессам получатьт меньше процессорного времени

### В более старщих версиях этого планировщика появилась возможность
* Если совападает, что процесс высокоприоритетный и еще и сильно интерактивный
  * Даже, когда он заканчивает свое выполнение, мы возвращаем процесс в конец этой же очереди
* Для обеспечения такого планирования вводится еще 1 коэфицент
  * Он оценивает то, что если мы будем разрешать процессу возвращатсья в ту же самую очередь, не приведет ли это к тому, что те процессы, которые ждут во 2 очереди.
  * И если коэффицент этого процесса будет выше какого-то порога, то мы скажем процессу, что в этот раз он должен будет уйти уже во 2 очередь

##### Поэтому мы гарантируем, что все процессы из 1 очереди попадут во 2
  * И когда это произойдет, мы просто поменяем указатели этих очередей, то есть свопнем их

##### Еще несколько вариантов, которые реализуются в этом планировании
* Для того, чтобы быстро находить очередь, в которой есть хоть один процесс, хранится битовый вектор размером в 140 бит, где если в этой очереди есть процесс, бит равен нулю и наоборот
* Таким образом, поиск следующего процесса на выполнение обеспечивается за счет поиска ближайшего не равного нулю бита в этой очереди
* Отсюда и название этого алгоритма

#### Возникла еще 1 проблема
> Если у нас будет достаточно приоритетный процесс, который будет постоянно порождать потоки, то эти потоки будут занимать верх приоритета очередей, что вызовет голодание более низкоприоритетных процессов
#### Придумали простую вещь
> Когда процесс порождает своего потомка, оставшееся время они делят пополам

#### Основная проблема этого алгоритма планирования
* Мы тратим накладные расходы на расчет коэффицента интерактивности

#### Появилась идея
* Использование гарантийного планирования (на основе его)
* Мы вводим 2 величины
  * execution_time
  * max_execution_time
* Когда процесс выполняется, мы увеличиваем его execution time
* max_execution_time для каждого процесса выводится для каждого процесса так, чтобы все было максимально справедливо
  * По сути это время ожидания деленое на колчиество процессов
* В каждый момент времени мы имеем массив, который упорядочен по execution_time
  * Каждый раз мы выбираем тот процесс, который меньше всего исполнялся. Даем ему возможность исполняться max_execution_time
  * Если он сам ушел в ожидание
    * Его execution_time стал меньше чем у тех, которые выполнялись в тот момент, когда он ждал
    * Таким образом этому процессу дадут сразу выполняться по возращении
  * Если процес довыполнил свой max_execution_time
    * Мы вынимаем самый левый процесс и смотрим сколько у max_execution_time по савнению с остальными
    * И ставим этот процесс в определенное место относительно этого параметра 

#### Как в такой модели изменять внешний приоритет
* Через изменение скорости, с которой вычисляется max_excution_time

Но как обеспечить скорость ? Ведь в таком случае нам нужно за O(n) искать куда вставить max_excution_time.
> Решили использовать красное черное дерево, что обеспечивает вставку и удаление за O(Log()n)
> Таким образом мы храним указатель на самый левый элемент дерева (самый маленький), это обеспечивает нам доступ за O(1)

Финальный планировщик называется __CFS__

#### Много процессорность и многопоточность
> Каждые 200 секунд мы перестраиваем процессы в очередях, перенося их с одного процессора на другой

---
## 20.  Взаимодействие процессов. Условия взаимоисключения и прогресса. Понятие критической секции. Голодание процессов.

####    Типология процессов.
         Процесс – это некоторая деятельность, связанная с исполнением программы на процессоре.
        При исполнении на центральном процессоре чаще всего различают:
        1. Порождение (подготавливаются условия для первого исполнения на процессоре)
        2. Активное состояние (программа исполняется на процессоре)
        3. Ожидание (программа не исполняется на процессоре по причине занятости какого-либо требуемого ресурса)
        4. Готовность (программа не исполняется, но для исполнения предоставлены все необходимые в текущий момент ресурсы, кроме центрального процессора)
        5. Окончание (нормальное или аварийное окончание исполнения программы, после которого процессор и другие ресурсы ей не предоставляются)Процесс находится в каждом из своих допустимых состояний в течение некоторого времени, после чего переходит в какое-то другое допустимое состояние. 

## 21.  Алгоритмы реализации взаимоисключений. Формальное описание алгоритмов, их недостатки.
---     хуй
## 22.  Семафоры Дейкстра. Решение проблемы «производитель-потребитель» с помощью семафоров.
---     хуй
## 23.  Проблемы взаимодействующих процессов. Проблема обедающих философов, проблема писателей и читателей.
        хуй
---
## 24.  Тупики. Условия возникновения и методы борьбы с тупиками.
## Тупики
* Может быть такая ситуация
* ![img](images/../imgs/Screenshot%202021-01-13%20at%2015.25.37.png)
  * Процесс 1 должен для своей работы использовать ресурс 1 и ресурс 2, причем его код написан так, что его критические секции имеют пересечение
  * Процесс 2 должен для своей работы использовать ресурс 1 и ресурс 2, причем его код написан так, что его критические секции имеют пересечение
  * В начальный момент времени ресурс 1 и 2 были свободны, и оба процесса их захватили, в какой-то момент времени, процесс Р0 решил, что ему нужно взять ресурс 2, но сделать он этого не может, поэтому он просто остановил свою работу
  * Процесс Р1 пользовался ресурсом 2 и в какой-то момент решил использовать ресурс 1, но ресурс 1 занят процессом Р0, и этот процесс тоже остановил свою работу
  * Не один из этих процессов не может продолжить работу и не может отдать ресурс обратно
  * Таким образом мы получаем бесконечный тупик

#### Проблема обедающих философов
* Есть стол за котором сидят 5 философов
* Перед каждым стоит тарелка со спагетти
* Философ может есть спагетти только 2 вилками
* вилок на столе ровно 5
#### Решение проблемы обедающих философов
* Выделим несколько состояний для философов
  * Может размышлять
  * Может находиться в состоянии голодания
  * Может есть

1. Каждый берет левую потом правую вилку
   * Может получиться так, что все философы поднимут левую вилку одновременно, то произойдет тупик
2. Возьми левую вилку
   1. Попытайся взять правую
   2. Если правую взять не удалось, положи обратно левую
   3. После чего попробуй повторить
   4. Таким образом получается live - lock
3. Можно сделать так же как во 2 случае, но ждать рандомно перед тем, как повторять действия
   1. Таким образом нет никакой гарантии, что процессы не выберут одинаковое время и не попадут в live - lock или dead - lock
4. Наличие официанта
   1. Кто-то должен разрешать и запрещать есть этим философам

#### Условия возникновения тупиков
1. Mutual exclusion - условие взаимоисключения
2. Условие ожидания ресурсов - hold and wait
   1. Если процесс взял ресурс, он имеет право его не отдавать и при этом просить некоторые следующие ресурсы
3. Условия не перераспределяемости -  No Preemtion
   1. Если мы выделили процессу ресурс, то мы не можем забрать его обратно
4. Условие кругового ожидания - Circle wait
   1. Процессы относительно 2 или более ресурсов встали в кольцевое ожидание

#### Как решить проблему возникновения тупиков
1. Игнорировать проблему - так как вероятность возникновения тупика очень маленькая
2. Пытаться предотвратить тупики
   1. Сделать организацию ос таким образом, что вышеупомянутые 4 условия никогда не выполнятся одновременно
3. Обнаружение тупиков и восстанавливаем после них
   1. Обнаруживаем тупик после того как он произошел
   2. После этого за счет каких-то механизмов восстанавливаем работоспособность (механизмы эти рассматривать не будем)

__Таким образом поняли, что наиболее эффективно будет пытаться предотвратить тупики__
__Но как ?__
* Mutal exclusion
  * В некоторых ситуациях можно разрешать 2 процессам пользоваться 1 неразделяемым ресурсом
* Можно нарушить условие hold and wait
  * Мы разрешаем процессу только в самом начале или когда он 1 раз просит тот или иной ресурс, сразу же просить все ресурсы от него
    * И либо даем ему все ресурсы сразу
    * Либо отказываем в даче ресурсов
  * Это можно использовать там, где не очень большое количество ресурсов
* Можно нарушить принцип отсутствия перераспределения
  * По какому-то принципу отбирать недостойный процесс и забирать у него ресурс, предварительно забуферизовав этот ресурс
  * Прямо как при прерывании
* Можно попытаться нарушить круговое ожидание
  * Можно пронумеровать все ресурсы
  * Мы разрешаем процессу брать ресурс только с номером, который выше чем номер самого ресурса

##### Проблема читателей и писателей
```
P0 -----(r)     --------(r)
P1      -------(r)
P2   ----(w)-------(w)
```

* Проблема в том, что процесс записи может уйти в вечное голодание из-за того, что постоянно будут появляться новые процессы на чтение
* __Решение__
  * Уложим требования на запись и чтение в очередь
---
## 25.  Принципы управления памятью вычислительной системы. Виртуальная память и преобразование адресов.

####Устройство памяти в компьютере
Память в компьютере (и внешняя память) устроена как линейное адресное пространство, состоящее из последовательности байтов. Так удобно работать только с железом, исходя из его особенностей.

Но программы устроены в виде модулей. Это удобно по следующим причинам:
* Модули могут быть __созданы и скомпилированы независимо друг от друга__. При этом если есть ссылки из одного модуля в другой, то система на этапе выполнения соединит необходимым образом ссылки.
* Разные модули могут получать __разный уровень безопасности__
* __Совместное__ использование модулей несколькими процессорами

Эффективное использование памяти - залог успеха. Объём памяти растет, но объем программ растет быстрее из-за говнокодеров.

Вообще пользователям хотелось бы самую быструю память, причем бесконечную. Но чем __быстрее взаимодействие__ в памяти, тем __дороже__ сама она. Это ещё один момент, почему необходимо использовать память эффективно. 

На самом деле, можно получить производительное устройство, не опираясь на конкретную технологию, а __создавая иерархию устройств__:
![img](https://sun9-21.userapi.com/impf/a2eUAdm6hI5sv-a2H4SX86bedmb0gjm1jzWFRQ/6ln1dEXqIiY.jpg?size=1402x766&quality=96&proxy=1&sign=e271f4f51ac9b46b6c72a24f86b0d9ff&type=album)


Здесь при перемещении слева направо происходит следующее:
* Снижается стоимость памяти
* Увеличивается объем памяти
* Время взаимодействие возрастает
* Частота обращения процессора уменьшается

Но и в данном случае не всё так гладко, как кажется. 

Допустим, мы хотим обратиться к первому уровню памяти. Всё будет хорошо, потому что процессор непосредственно с ней работает.

Теперь же мы хотим обратиться ко второму уровню. Для этого нам необходимо будет обратиться к первому типу памяти, а потом обратиться уже ко второму. Так ещё мы обращаемся с блоком данных, что ведет за собой дополнительные расходы. Можно придти к выводу, что такая организация памяти имеет большее время работы, нежели если бы у нас был только один тип памяти. 

На самом деле __всё напрямую зависит от оперативной памяти__, потому что она __ограничивает__ круг задач, которые могут выполняться __одновременно__.

Но что делать, если оперативная память будет занята полностью?

Тут и придумали такой способ организации памяти, при котором образы некоторых процессов полностью или частично выгружаются на жесткий диск.

####Виртуализация ОЗУ
Конечно, выгружать стоит на диск только __неактивные процессы__, или __ожидающие__ каких-либо ресурсов. Когда подходит очередь процесса на диске, он выгружается в оперативную память (при этом, если ОЗУ занята, то на диск загружается другой процесс).

Такая подмена памяти называется __виртуализацией__. Она позволила повысить уровень мультипрограммирования, потому что ОЗУ теперь не так сильно ограничивает количество одновременно выполняющихся процессов.

__Виртуализация ОЗУ__ осуществляется совокупностью программных и аппаратных средств __автоматически, прозрачно для приложения__.

__Виртуализация ОЗУ__ возможна благодаря двум подходам: __swapping и virtual memory__.

####Virtual Memory
Между ОЗУ и диском перемещаются __части__ образов (сегменты, страницы, блоки т.д.) процессов.

__Виртуальная память__ - это моделирование ОЗУ во внешней памяти. 

Механизм, который позволяет связывать виртуальные и физические адреса - __динамическое преобразование адресов (ДПА)__.
Динамическое преобразование адресов 
Компьютер на этом этапе уже выступает как __логическое устройство__, а не как __уникальное физическое__.

####Важно понимать, что смежные виртуальные адреса не обязательно смежны в реальности.

Механизм ДПА предполагает ведение таблиц, в которых показываются какие ячейки вычислительного процесса и где находятся в ОЗУ.

Индивидуальное отображение каждой ячейки не имеет смысла, поэтому отображают их сразу блоками.

Разные размеры блоков порождают разные ситуации: большие блоки создают меньшие таблицы для отображения блоков, но увеличивает время обмена и наоборот, меньшие блоки создают большие таблицы, но уменьшают время обмена. 

Блоки могут быть фиксированного размера (__страницы__) и динамического (__сегменты__).

Один из способов организации виртуальный памяти - страничная.

Хорошо, у нас есть способ организации памяти, но как ей управлять? Есть три стратегии.

#####Стратегия вталкивания.
Принимает решение, __когда стоит переписать__ страницу или сегмент из ВП в ОЗУ. 

Допускается два вида этой стратегии:
* __Вталкивание по запросу__ - система ожидает ссылки на страницу от процесса (поиск из-за этого становится очень быстрым, но среднее время ожидания увеличивается)
* __Упреждающее вталкивание__ - система прогнозирует выталкивание страницы (сокращается время ожидания)

#####Стратегия размещения
Определяет, __куда поместить__ поступающую страницу. Очевидно: в любой свободный блок для страниц. Для сегментов используются стратегии ОЗУ.
#####Стратегия выталкивания 
Определяется, __какую страницу__ нужно удалить из ОЗУ для освобождения места под новую страницу. 

Но какую именно страницу нужно удалить, определяется одним из способов:
* __Выталкивание первой пришедшей страницы__ (по аналогии с FIFO) - нужны временные метки для каждой страницы (можно удалить активно использующиеся страницы, что плохо)
* __Выталкивание дольше всего не используемых страниц__ - опять нужны временные метки, которые ещё и нужно обновлять каждый раз
* __Выталкивание реже всего используемых страниц__ - нужно считать количество обращений (менее затратно, чем предыдущий способ, но тоже не рационально)
* __Выталкивание не использующихся в последнее время страниц__ - использует два аппаратных бита на страницу: флаг обращения, флаг модификации. Если не было изменений на странице - удалить.




---
## 26.  Методы распределения оперативной памяти без использования внешней памяти.

- ***Распределение памяти фиксированными разделами***

  Во время старта системы генерируется размер разделов на которые разделяется вся ОЗУ.

  Каждый новый процесс попадает в очередь (общую или к конкретному разделу). ОС выгружает завершившиеся или перешедшие в ожидание процессы из памяти и загружает новые.

  Разделы могут быть как одинакового размера, так и разного (важно, что их размер и количество определяется при старте). При разделах одинакового размера очередная задача просто загружается в любой свободный. При разделах разного размера задача загружается в минимальный свободный раздел, который может ее вместить.

  Недостаток этой системы в жёстком (неэффективном распределении памяти): в одном разделе может выполняться только одна программа, даже если она очень маленькая, поэтому остается много свободного пространства. Это явление называют внутренней фрагментацией.

  Еще одним недостатком является ограниченность размера раздела. Если программа занимает больше места, чем самый большой раздел, то она не сможет быть выполнена. Поэтому программист должен проектировать программу так, чтобы в каждый момент времени она занимала только один раздел ОП.


- ***Распределение памяти разделами переменной величины***
  
  Система заранее не делит память на разделы. По мере поступления задач выделяется необходимая память. После того, как задача завершилась, она удаляется и на ее место помещается новая задача. 
  
  На схеме видно, что по мере выгрузки процессов из памяти и загрузки новых появляется много небольших свободных зон, в которые уже не могут поместиться новые процессы. Это явление называется внешней фрагментацией.

  [img]('..imgs/26.png');

  

- ***Перемещаемые разделы***

  Суть этого метода заключается в том, что разделы динамически распределяются в памяти так, чтобы образовывалась одна непрерывная свободная область памяти. Уплотнение может происходить при каждом завершении процесса, или если новому процессу не нашелся достаточно большой свободный участок.

  Хоть память и используется эффективно, но алгоритм требует больше времени для устранения фрагментов, что перевешивает преимущество данного метода. 

---
## 27.  Страничная организация виртуальной памяти. Вычисление физических адресов при страничной организации виртуальной памяти.
Большинство систем виртуальной памяти используют технику, называемую страничной организацией памяти.

__Страничная память__
Способ организации виртуальной памяти, при котором единицей отображения виртуальных адресов на физические является регион постоянного размера (т.е страница). Размер страницы обычно выбирается равным степени двойки, это позволяет упростить механизм преобразования адресов. Стандартный размер страницы у современных ОС = 4096 байт.

В общем случае размер виртуального пространства не кратен размеру страницы, поэтому последнюю страницу дополняют фиксированной областью.

__Таблица страниц для процесса__
Для каждого процесса ОС создает таблицу страниц - информационную структуру, содержащую записи обо всех виртуальных страницах процесса.
Запись таблицы включает в себя следующую информацию:
* __Номер физической страницы ( N ф.с)__, в которую загружена данная виртуальная страница.
* __Признак присутствия M(memory)(в схеме P)__, равный единице, если данная страница находится в оперативной памяти и нулю, если страница находится в файле подкачки на диске.
* __Признак модификации страницы W(write)(в схеме D)__, устанавливаемый в единицу всякий раз, когда производится запись по адресу, относящемуся к данной записи в таблице, то есть к данной страницы. Если этот бит равен нулю, что означает, что страница не изменялась с последнего обращения к ней, то эту страницу можно не перезаписывать на диске (при наличии файла подкачки). 
* __Признак обращения А(access) к странице__, называемый также битом доступа, устанавливаемый в единицу, при каждом обращении по адресу, относящемуся к этой странице.
* __Другие управляющие биты(в схеме W)__ служащие для целей защиты или совместного использования памяти на уровне страниц.

![img](https://sun9-53.userapi.com/impg/4ahDF35WlgizIDsqhPCEGbWvUDdwWY5n_BJp1Q/bimfeCG9zho.jpg?size=1060x564&quality=96&proxy=1&sign=1e9b3ff5487cf127ee96bfcfc2898689&type=album)

Виртуальный адрес при страничном распределении может быть представлен в виде пары (p, s).  
  * p - номер виртуальной страницы процесса (нумерация страниц начинается с 0) 
  * s - смещение в пределах виртуальной страницы.
  
При записи в двоичном представлении - p - старшие разряды, s - младшие (их количество определяется степенью 2 в размере страницы). 
  
При преобразования виртуального адреса в физический на основании виртуального адреса p по таблице определяется физический, к нему добавляется смещение s. Адрес таблицы хранится в специальном регистре. При страничной организации памяти много времени может тратиться на страничное прерывание, на преобразование виртуального адреса в физический. Для уменьшения количества прерываний и уменьшения размеров таблиц можно увеличить размер страницы, однако это увеличивает фиктивную область последней виртуальной страницы каждого
процесса.

---
## 28.  Методы оптимизации потребления ресурсов при страничной организации виртуальной памяти. Сегментно-страничная организация виртуальной памяти.
---
## 29.  Методы организации хранения данных в файловых системах: непрерывная последовательность блоков, связный список, таблица размещения файлов.

Метод выделения дискового пространства - это способ связывания файлов с блоками на диске.

__Методы адресации блоков__
* Методы адресации блоков
* Непрерывная последовательность блоков;
* Связный список;
* Таблица размещения файлов.

__Непрерывная последовательность блоков:__ 
* Каждый файл представляется последовательностью блоков, которые записываются на диск друг за другом. На диске так же хранится словарь, отображающий имя файла, ссылку на начальный блок и количество блоков, занимаемых этим файлом.
* Словарь (вполне вероятно, это запись о файле в каталоге)

![img](https://sun9-74.userapi.com/impg/8fa8KSCmNuUeFVHA0uNxYr43JIi04lt1Nk8w1g/49OXSPM5IcY.jpg?size=1358x658&quality=96&proxy=1&sign=07dd5fe7562ef789725c7f1178052a7d&type=album)


__Плюсы__
* Легкость реализации
* Высокая производительность (все блоки идут последовательно и могут быть считаны за один проход)
* Данные можно восстановить (удаления как такового не происходит, данные просто перезаписываются, когда возникает необходимость)

__Минусы__
* Возникает фрагментация, что уменьшает производительность при записи, а то и вообще привести к невозможности записи нового файла
* Проблемы при записи файла, размер которого изменился после начала записи(из-за того, что каждому файлу соответствует запись в словаре, с его адресом начала и количеством блоков, которые он занимает). То есть с копирование готовых файлов всё будет в порядке, но изменять эти файлы на диске уже будет нельзя.

__Использование__
* Используется в статичных накопителях, например, дисковых (CD, DVD)


---
## 30.  Методы организации хранения данных в файловых системах: индексные дескрипторы.

####ext 2 - Extended File System
Жесткий диск разбивается на блоки по порядку:
  * Суперблок - это блок данных, который содержит общую информацию о файловой системе, например, об ее архитектуре, общем числе блоков и индексных дескрипторов, или метаданных
  * Битовая карта блоков (количество бит – количество блоков на диске) показывает свободное место на диске
  * Битовая карта для i-nods, чтобы знать какие i-node свободны
  * I-nods (разбивается на блоки по количеству файлов): метаданные, 15 блоков под адреса - каждый по 4 байта
    * первые 12 – блоки прямой адресации, 
    * 13 - косвенная адресация 
    * 14 - двойная косвенная адресация
    * 15 - тройная косвенная адресация

Косвенная адресация подразумевает под собой ссылку на массив ссылок на кластеры данных (двойная содержит ссылку на массив ссылок, которые указывают на массив ссылок на кластеры, тройная ещё добавляется уровень ссылок).

На каждом уровне может быть максимум 1024 записи. 

Такая система позволяет хранить файлы размером до 2 Тб.
data i-node(блоки с данными)

//вставить таблицу 

__I-node или индексный узел (или индексный дескриптор)__ - это таблица, связанная с файлом, в которой хранятся атрибуты файла и дисковые адреса блоков файла.

####Оценка:
\+ Надёжность – потеряли 1 i-node – потеряли 1 файл, а не всё.
\+ Каталог хранит только 2 поля: имя и i-node, без размера.
\+ Эта модель позволила создать сетевой каталог.
\+ Суперблок хранит метаданные всей системы.
\- Заранее ограничено количество файлов.

####NTFS 
В отличии от ext2 граница между i-nods и data может изменятся, то есть можно записывать файлов больше, чем задумано. Это ненадежно и медленно, зато мы получаем более гибкое управление дисковым пространством. (Ещё вроде как появилась журналируемость, но это не главное)

####ext 3
* Появилась журналируемость – заплатим производительностью за надежность. Сначала пишем план того, что я собираюсь сделать с файлом, потом его выполнять и стирать план. При сбое все можно будет восстановить.
* Более чем, в 2 раза увеличивается время записи, поэтому сделали 3 вида журнала:
  * journal – пишу все
  * write back – в журнал пишутся только метаданные о системе
  * ordered – тоже что и write back, но сначала изменения пишутся в журнал 

####ext 4
* Максимальный размер 1 раздела диска – 1 эксабайт (2 в 60 степени байт). Для того, чтобы ускорить запись остается немного места в конце – одежда на вырост.
* Добавили в структуру хеш, который позволяет увеличить скорость поиска файла.
* Введение механизма пространственной (extent) записи файлов, уменьшающего фрагментацию и повышающего производительность. Суть механизма заключается в том, что новая информация добавляется в конец области диска, выделенной заранее по соседству с областью, занятой содержимым файла.




---
## 31.  Журналируемые файловые системы. Назначение и виды журналов.

Файловая система, в которой осуществляется ведение журнала, хранящего список изменений, в той или иной степени помогающего сохранить целостность файловой системы при сбоях.

### Зачем нужны журналируемые файловые системы?

При отсутствии журнала все изменения проводились сразу на диске, но кроме проведения каких-то действий нужно было ещё и изменять метаданные (ссылки на файл и т.д.). Если при этом произойдёт сбой, то будет известно лишь то, что он был, но не в чём он заключался. Журналирование позволяет избежать этой проблемы, и не придётся проверять диск при наличии сбоя целиком, только просмотреть журнал.

TL;DR: при падении ты теряешь не все данные на диске, а только маленькую часть, и не нужно делать CHKDSK

Существует три вида журналов, которые мы рассмотрим на примере файловой системы ext3 (в файловой системе NTFS используются те же типы журналов, но у пользователя нет возможности контролировать режимы - для каждого файла выбор режима отдаётся на откуп драйверу файловой системы):

### Режим data=writeback
  __Принцип работы:__
  В журнал записываются только метаданные - то есть информация об изменениях файловой системы, а не сами файлы. 
  __Оценка:__
  \+ Наилучшая среди журналируемых файловых систем производительность. 
  \- Наименьшая надёжность. При возникновении ошибок или внезапного завершения работы могут быть ошибки в метаданных, поэтому возможности восстановления данных практически нет.

### Режим data=ordered
  В режиме data=ordered файловая система ext3 журналирует не только метаданные, но и логические метаданные и блоки данных группируются в единый модуль, называемый транзакцией (transaction). Перед записью новых метаданных на диск, связанные блоки данных записываются первыми.Режим data=ordered решает проблему с разрушением данных, свойственную режиму data=writeback и большинству других журналируемых файловых систем. 

  #### Гарантия от разрушения данных: 
  При добавлении данных в конец файла режим data=ordered гарантированно обеспечивает целостность (как при полном журналировании). Однако если данные в файл пишутся поверх существующих, то есть вероятность перемешивания "оригинальных" блоков с модифицированными. Это результат того, что data=ordered не отслеживает записи, при которых новый блок ложится поверх существующего и не вызывает модификации метаданных. В режиме data=ordered порядок записи отслеживается только до попадания в кэш жесткого диска. Такое ограничение не должно огорчать пользователей, так как операция добавления в конец файла более обычна, чем наложение записи. 

  __Оценка:__
  \+ Обеспечивает большую надёжность данных. (по сравнению с writeback) При записи в конец файла гарантированно обеспечивает целостность. 
  \+ Обеспечивает лучшую производительность (по сравнению с journal). Так как журналируются только метаданные, потери в производительности небольшие.
  \- Производительность меньше, чем у writeback.
  \- Надёжность меньше, чем у journal. 
Золотая середина, в ext3 этот режим включен по умолчанию.

### Режим data=journal
  Режим data=journal обеспечивает полное журналирование и метаданных, и самих данных. Все новые данные сначала пишутся в журнал и только после этого переносятся на свое постоянное место. В случае аварийного отказа журнал можно повторно перечитать, приведя данные и метаданные в непротиворечивое состояние.
  Теоретически, режим data=journal самый медленный из всех режимов журналирования, так как данные записываются на диск два раза. 

__Плюсы:__
Обеспечивает лучшую надёжность данных. (при загрузке после падения все изменения могут быть восстановлены по записи в журнале)

__Минусы:__
Наименьшая производительность. Все данные должны быть записаны дважды (один раз в журнал, один раз в саму файловую систему). 

---
## 32.  Обоснование необходимости и принципы построения распределенных ОС.
---
## 33.  Алгоритмы управления памятью в распределенных ОС. Их преимущества и недостатки.

1. Память с центральным сервером. Все разделяемые данные поддерживает центральный сервер.
    
    \+ Простота в реализации алгоритма
    
    
    \- Сервер может стать узким местом

2. Миграция страниц. Страничный обмен с другим узлом в котором, рассполагается необходимая
страница.

    \+ Консистентность данных - данные существуют в одном экземпляре
    
    \- Trashing - два узла могут спорить за одну страницу и всё время перемещать её друг другу.
    ⇒ Частичное решение: timeout после перемещения страницы


3. Метод размножение для чтения. Страничное копирование с другим узлом в котором, рассполагается необходимая страница

\+ Производительность: возможность одновременного доступа по чтению

\- Большой расход памяти: храним дубликаты одних и тех же данных на разных узлах

\- Время: поиск данных.
⇒ Решение: записать в список узы кому отдали страницу.
Проблема: может быть очень большой связный список.
⇒ Решение: у каждого узла запрашивать о наличии страницы.
Проблема: дополнительная нагрузка на узлы.

\- Запись: протеричивые данные
⇒ Решение: кидаем всем узлам сообщение убить страницу.
Проблема: коллизия если два узла делают запись.

1. Память с центральным сервером. Все разделяемые данные поддерживает центральный сервер.
    
    \+ Простота в реализации алгоритма
    
    
    \- Сервер может стать узким местом

2. Миграция страниц. Страничный обмен с другим узлом в котором, рассполагается необходимая
страница.

    \+ Консистентность данных - данные существуют в одном экземпляре
    
    \- Trashing - два узла могут спорить за одну страницу и всё время перемещать её друг другу.
    ⇒ Частичное решение: timeout после перемещения страницы


3. Метод размножение для чтения. Страничное копирование с другим узлом в котором, рассполагается необходимая страница

    \+ Производительность: возможность одновременного доступа по чтению

    \- Большой расход памяти: храним дубликаты одних и тех же данных на разных узлах

    \- Время: поиск данных.
    ⇒ Решение: записать в список узы кому отдали страницу.
    Проблема: может быть очень большой связный список.
    ⇒ Решение: у каждого узла запрашивать о наличии страницы.
    Проблема: дополнительная нагрузка на узлы.

    \- Запись: протеричивые данные
    ⇒ Решение: кидаем всем узлам сообщение убить страницу.
    Проблема: коллизия если два узла делают запись.

4. Метод полного размножение. Разрешим всем процессам вносить изменения и всем сообщать,
что мы внесли изменения.

    \- Модификации могут быть противоречивые
    ⇒ Решение: сервер нумерации, который получает модификацию, присваивает номер странице и рассылает всем узлам

---
## 34.  Методы управление файлами и каталогами в распределенных ОС. Их преимущества и недостатки.
---
## 35.  Синхронизация времени в распределенных системах. Метод Лампорта для синхронизации времени.


---
## 36.  Технологии виртуализации. Виды виртуализации: эмуляция аппаратуры, полная виртуализация, паравиртуализация, виртуализация уровня ядра операционной системы. Их достоинства и недостатки.

Технологии виртуализации решают задачи распределения pool’a ресурсов между множеством потребителей так, чтобы эти ресурсы были распределены по множеству узлов. Облачные решения основываются на технологиях виртуализации.

Изначальные основные задачи виртуализации:

1. Возможность поддержки устаревших ОС и приложений
2. Повышение отказаустойчивости и надежности
3. Созание средств для тестирования ПО
4. Консалидация серверов
5. Повышение управляемости и надежности сетевой инфраструктуры

Виды:

1. Эмуляция аппаратуры: 


    \+ Нет ограничений в архитектуре

    \+ Можем работать не модифицируя приложение в GUEST OS

    \- Производительность: приложение делает системный вызов в HOST OS

    \- Память: пересчёт памяти несколько раз

2. Полная виртуализация:

    \+ Нет ограничений в архитектуре

    \+ Можем работать не модифицируя приложение в GUEST OS

    \- Производительность
    
    \- Потребность драйверов для Hyper-visor
    
    \- Архитектура HOST OS и GUEST OS должна
    быть совместима с архитектурой аппаратного узла

3. Паравиртуализация:

    \+ Нет ограничений в архитектуре
    
    \+ Можем работать не модифицируя приложение в GUEST OS

    \- Производительность
    
    \- Архитектура HOST OS и GUEST OS должна
    быть совместима с архитектурой аппаратного узла
    
4. Виртуализация уровня ядра (Контейнеризация):

    \+ Производительность: Высокая эффективность использования аппаратных ресурсов
    
    \- Соместимость: Контейнеры должны быть
      совместимы по ядру, т.е отсутвует возможность запуска на одном узле ОС
      разного типа (Windows и Linux)
    
    \- Безопастность: Сбой на уровне ядра затронет все компоненты